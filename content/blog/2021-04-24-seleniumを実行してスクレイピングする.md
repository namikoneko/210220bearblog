---
title: seleniumを実行してスクレイピングする
slug: execute-selenium
date: 2021-04-24T15:25:49.769Z
description: seleniumを実行してスクレイピングしたときのメモです。
tags:
  - python
  - scraping
---
## 公式7.20. Remote WebDriver
<https://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webdriver>

## Pythonでseleniumを用いたスクレイピング
<https://qiita.com/yutaiii/items/0be6671fbaea842d9a38>

xpathの使い方。

## コード

これでリンクをたどることができた

```
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
import time

options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
driver = webdriver.Chrome(options=options)

driver.get("https://210220bearblog.netlify.app/blog/")
time.sleep(1)

driver.find_element_by_xpath('/html/body/main/content/ul[1]/li[1]/a').click()
print(driver.current_url)

driver.close()
driver.quit()

```

## BeautifulSoupとSeleniumを組み合わせた自動テストの方法（Python）

<https://qiita.com/momotar47279337/items/ce4ec8aed21cccd8ca5a>


```
source = driver.page_source
soup = BeautifulSoup(source,'html.parser')
HTMLデータの取得にSeleniumの「.page_source」を使えば問題ありません。
```

BeautifulSoupと組み合わせることができるらしい

## Seleniumを安定稼働させるために行うべき３つの設定(Headlessモードにも対応)

<https://tanuhack.com/stable-selenium/>